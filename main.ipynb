{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:41:50.246694Z",
     "start_time": "2023-11-27T23:41:50.201116Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so, 0x0002): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: <8D36263D-A690-33C2-92FC-5C2A03029529> /Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: tried: '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/Mehrdadi/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/Mehrdadi/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/local/lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/lib/_pywrap_tensorflow_internal.so' (no such file, not in dyld cache)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zc/lhpyx9cd2pdg5g1k0srmc8880000gp/T/ipykernel_74931/4144405524.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mnltk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstem\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mWordNetLemmatizer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mSequential\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mDense\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDropout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msys\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_sys\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtools\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmodule_util\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_module_util\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlazy_loader\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLazyLoader\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_LazyLoader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[0;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meager\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpywrap_tensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_pywrap_tensorflow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotobuf\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mconfig_pb2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotobuf\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mrewriter_config_pb2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpywrap_tfe\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtf2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpywrap_tf_session\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/pywrap_tfe.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpywrap_tensorflow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pywrap_tfe\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m: dlopen(/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so, 0x0002): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: <8D36263D-A690-33C2-92FC-5C2A03029529> /Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: tried: '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/Mehrdadi/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/Mehrdadi/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/Mehrdadi/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/local/lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/lib/_pywrap_tensorflow_internal.so' (no such file, not in dyld cache)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Mehrdadi/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/Mehrdadi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:42:01.052020Z",
     "start_time": "2023-11-27T23:41:59.349456Z"
    }
   },
   "id": "d642a8d311fb98d8"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "data_file = open('intents.json')\n",
    "data = json.load(data_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:42:03.935552Z",
     "start_time": "2023-11-27T23:42:03.929112Z"
    }
   },
   "id": "4562204696664239"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Identifying Feature and Target for the NLP Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9f3072daa01f64e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "words = []\n",
    "classes = []\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        tokens = nltk.word_tokenize(pattern)\n",
    "        words.extend(tokens)\n",
    "        data_X.append(pattern)\n",
    "        data_y.append(intent[\"tag\"])\n",
    "        \n",
    "    if intent[\"tag\"] not in classes:\n",
    "        classes.append(intent[\"tag\"])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n",
    "words = sorted(set(words))\n",
    "classes =sorted(set(classes))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:42:06.665218Z",
     "start_time": "2023-11-27T23:42:06.650672Z"
    }
   },
   "id": "8b8dab3f9c7f1fe3"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "training = []\n",
    "out_empty = [0] * len(classes)\n",
    "# creating the bag of words model\n",
    "for idx, doc in enumerate (data_X):\n",
    "    bow = []\n",
    "    text = lemmatizer. lemmatize(doc. lower ())\n",
    "    for word in words:\n",
    "        bow. append(1) if word in text else bow. append (0)\n",
    "\n",
    "    output_row = list(out_empty)\n",
    "    output_row[classes.index(data_y[idx])] = 1\n",
    "    # add the one hot encoded Boll and associated classes to training\n",
    "    training. append ([bow, output_row])\n",
    "\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array (training, dtype=object)\n",
    "# split the features and target labels\n",
    "train_X = np.array(list(training[:, 0]))\n",
    "train_Y = np. array(list(training[:, 1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:42:09.932401Z",
     "start_time": "2023-11-27T23:42:09.917533Z"
    }
   },
   "id": "13745a210218c935"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zc/lhpyx9cd2pdg5g1k0srmc8880000gp/T/ipykernel_74931/722395923.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSequential\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_X\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"relu\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m64\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"relu\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_X[0]),), activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len (train_Y[0]), activation = \"softmax\"))\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())\n",
    "model.fit(x=train_X, y=train_Y, epochs=150, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:42:10.624247Z",
     "start_time": "2023-11-27T23:42:10.613738Z"
    }
   },
   "id": "5dc00513433219f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_text (text):\n",
    "    tokens = nltk. word_tokenize (text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "def bag_of_words (text, vocab):\n",
    "    tokens = clean_text (text)\n",
    "    bow = [0] * len(vocab)\n",
    "    for w in tokens:\n",
    "        for idx, word in enumerate (vocab):\n",
    "            if word == w:\n",
    "                bow[idx] = 1\n",
    "    return np.array (bow)\n",
    "\n",
    "\n",
    "def pred_class (text, vocab, labels):\n",
    "    bow = bag_of_words (text, vocab)\n",
    "    result = model. predict (np.array ([bow]))[0] #extracting probabilities\n",
    "    thresh = 0.5\n",
    "    y_pred = [[indx, res] for indx, res in enumerate (result) if res > thresh]\n",
    "    y_pred.sort(key=lambda x: x[1], reverse=True) #Sorting by values of probability in dec\n",
    "    return_list = []\n",
    "    for r in y_pred:\n",
    "        return_list.append(labels[r[0]]) #Contains labels (tags) for highest probability \n",
    "    return return_list\n",
    "\n",
    "def get_response(intents_list, intents_json):\n",
    "    if len(intents_list) == 0:\n",
    "        result = \"Sorry! I don't understand.\"\n",
    "    else:\n",
    "        tag = intents_list[0]\n",
    "        list_of_intents = intents_json[\"intents\"]\n",
    "        for i in list_of_intents:\n",
    "            if i[\"tag\"] == tag:\n",
    "                result = random. choice(i[\"responses\"])\n",
    "                break\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9249ca497f8baa35"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
